{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance segmentation evaluation\n",
    "\n",
    "Test a Detector on A Customized Dataset (here, I use the Mask RCNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from detectron2.data.datasets import register_coco_instances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model path\n",
    "# SC_FTAL_F2_80%_best\n",
    "model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SSL_SC_FTAL_F2/Train_80%/model_best_89.1765.pth\"\n",
    "model_config_path = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SSL_SC_FTAL_F2/Train_80%/config.yaml\"\n",
    "\n",
    "# baseline_FTAL_F2_80%_best\n",
    "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SL_F2_2/Train_80%/model_best_91.1003.pth\"\n",
    "# model_config_path = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SL_F2_2/Train_80%/config.yaml\"\n",
    "\n",
    "# SW_FTAL_F2_80%_best\n",
    "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SSL_SwAV_FTAL_F2_1/Train_80%/model_best_89.6902.pth\"\n",
    "# model_config_path = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SSL_SwAV_FTAL_F2_1/Train_80%/config.yaml\"\n",
    "\n",
    "# model_checkpoint_path = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SL_F2_2/Train_100%/model_best_74.8527.pth\"\n",
    "# model_config_path = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SL_F2_2/Train_100%/config.yaml\"\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_config_path)\n",
    "cfg.MODEL.WEIGHTS = model_checkpoint_path \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register my custom test dataset\n",
    "\n",
    "dataset should be in COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Pollutant_test dataset\n",
    "register_coco_instances(\"Pollutant_test\", {}, \"/scratch/tjian/Data/Peng_SSL/SL_test/annotations/test.json\", \"/scratch/tjian/Data/Peng_SSL/SL_test/test/\")\n",
    "Test_Dataset_name=\"Pollutant_test\"\n",
    "Class_name=[\"entrap bean\", \"free bean\"]\n",
    "# Class_name=[\"entrapped particle\", \"free particle\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Predict one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"XXX.jpg\")\n",
    "outputs = predictor(im)\n",
    "# print(outputs) # It will print num_instances, box location, scores, prediction labels\n",
    "\n",
    "v = Visualizer(im,\n",
    "               MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name),\n",
    "               instance_mode=ColorMode.SEGMENTATION,\n",
    "               scale=1.0\n",
    "               )\n",
    "\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))  # do not write \"gpu\"\n",
    "img=out.get_image()\n",
    "result=cv2.imwrite(r\"XXX/predict.jpg\", img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Predict images in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define the folder path \n",
    "folder_path = r\"/scratch/tjian/Data/Peng_SSL/IV-raw/\"\n",
    "\n",
    "\n",
    "# define output folder of predicted images\n",
    "out_path = r\"/scratch/tjian/Data/Peng_SSL/IV-raw_pred/\"\n",
    "# out_path = r\"/scratch/tjian/Data/Pollutant_SSL/Predicted/SW_FTAL_F2_80%_best/\"\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "for filename in file_names:\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            out_file_name= os.path.join(out_path, filename)\n",
    "            im = cv2.imread(image_path)\n",
    "            # start predicting\n",
    "            outputs = predictor(im)\n",
    "            print(outputs)\n",
    "            print(len(outputs[\"instances\"].get(\"pred_boxes\")))\n",
    "            v = Visualizer(im,\n",
    "                           MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name),\n",
    "                           instance_mode=ColorMode.SEGMENTATION,\n",
    "                           scale=1.0\n",
    "                           )\n",
    "            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))  # do not write \"gpu\"\n",
    "            img=out.get_image()\n",
    "            result=cv2.imwrite(out_file_name, img)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Test on a test dataset with labels\n",
    "\n",
    "Run a model to predict images with ground-truth labels and output the accuracy, e.g., AP50\n",
    "\n",
    "Note: the default output of metric per class is AP@50:5:95. \n",
    "\n",
    "If you want to output AP50 the metric per class, you need to change the code \"precision = precisions[:, :, idx, 0, -1]\" to \"precision = precisions[0, :, idx, 0, -1]\" in detectron2/evaluation/coco_evaluation.py (Line 358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# define the test dataset path\n",
    "\n",
    "save_evaluate_file_dir = \"/scratch/tjian/PythonProject/deep_pollutant_SSL/checkpoints/train_weights/SSL_SC_FTAL_F2_2/Train_40%/test_results/\"\n",
    "\n",
    "# create the \"save_evaluate_file_dir\" if they do not exist\n",
    "if not os.path.isdir(save_evaluate_file_dir):\n",
    "    os.mkdir(save_evaluate_file_dir)\n",
    "\n",
    "evaluator = COCOEvaluator(Test_Dataset_name, output_dir=save_evaluate_file_dir)\n",
    "val_loader = build_detection_test_loader(cfg, Test_Dataset_name)\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Output accuracy according to prediction and ground-truth files\n",
    "\n",
    "Compare predictions file (json file) and ground-truth files (json file), and output the accuracy, e.g., AP50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Load ground truth annotations\n",
    "coco_gt = COCO('XXX/test.json')\n",
    "\n",
    "# Load detection results\n",
    "coco_dt = coco_gt.loadRes('/scratch/tjian/Data/XXX/test_1/test_PR/SSL_pred_results_NMS_0.1/coco_instances_results.json')\n",
    "\n",
    "# Create COCOEval object\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "\n",
    "# Run evaluation\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "# Get precision and recall values at different IoU thresholds\n",
    "precision = coco_eval.eval['precision']\n",
    "recall = coco_eval.eval['recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Output confusion matrix on test dataset with annotations, i.e., TP, FP, FN\n",
    "\n",
    "See the \"main_Confusion_matrix_OD.ipynb\", but it is not used in this work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Calculate the FP on a dataset without particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define the folder path \n",
    "folder_path = r\"XXX\"\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "FP = 0\n",
    "for filename in file_names:\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            im = cv2.imread(image_path)\n",
    "            # start predicting\n",
    "            outputs = predictor(im)\n",
    "            # print(outputs)\n",
    "            # print(len(outputs[\"instances\"].get(\"pred_boxes\")))\n",
    "            FP = FP + len(outputs[\"instances\"].get(\"pred_boxes\"))\n",
    "\n",
    "print(\"FP (include free and entrapped particles): \", FP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Predict images in a folder, and output the bbox and mask in an excel file\n",
    "\n",
    "Note: this script works in Linux system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# define the folder path \n",
    "folder_path = r\"/scratch/tjian/Data/Peng_SSL/IV-count/\"\n",
    "\n",
    "# define output folder of predicted images\n",
    "out_path = r\"/scratch/tjian/Data/Peng_SSL/IV-count_pred/\"\n",
    "\n",
    "# define the path of excel file\n",
    "excel_file_path = r\"/scratch/tjian/Data/Peng_SSL/IV-count_pred.xlsx\"\n",
    "\n",
    "# Initialize a list to hold the data for each instance\n",
    "data = []\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "for filename in file_names:\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            out_file_name= os.path.join(out_path, filename)\n",
    "            im = cv2.imread(image_path)\n",
    "            # start predicting\n",
    "            outputs = predictor(im)\n",
    "            # print(outputs)\n",
    "            # print(\"#######################################\")\n",
    "            \n",
    "            # Extract the instances\n",
    "            instances = outputs['instances']\n",
    "            \n",
    "            # Extract bounding boxes (x1, y1, x2, y2) from 'pred_boxes'\n",
    "            pred_boxes = instances.pred_boxes.tensor.cpu().numpy()\n",
    "            # print(\"Bounding Boxes:\", pred_boxes)\n",
    "            \n",
    "            # Extract scores from 'scores'\n",
    "            scores = instances.scores.cpu().numpy()\n",
    "            # print(\"scores:\", scores)\n",
    "            \n",
    "            # Extract classes from 'pred_classes'\n",
    "            pred_classes = instances.pred_classes.cpu().numpy()\n",
    "            # print(\"classes:\", pred_classes)\n",
    "            \n",
    "            # Extract masks and calculate mask areas from 'pred_masks'\n",
    "            pred_masks = instances.pred_masks\n",
    "            mask_areas = pred_masks.sum(dim=(1, 2)).cpu().numpy()  # Sum over height and width dimensions\n",
    "            # print(\"Mask Areas:\", mask_areas)\n",
    "            \n",
    "            # Loop through each instance and get the bounding box and area\n",
    "            for i in range(len(outputs[\"instances\"].get(\"pred_boxes\"))):\n",
    "                class_id = pred_classes[i]\n",
    "                score = scores[i]\n",
    "                bbox = pred_boxes[i]\n",
    "                mask_area = mask_areas[i]\n",
    "                bbox_area= (bbox[2]-bbox[0])*(bbox[3]-bbox[1])\n",
    "                print(f\"Instance {i+1}: Class = {class_id}, Score = {score:.4f}, BBox = {bbox}, bbox_area = {bbox_area}, Area = {mask_area}\")\n",
    "                data.append([filename, class_id, score, bbox[0], bbox[1], bbox[2], bbox[3], bbox_area, mask_area])\n",
    "            \n",
    "            # output predicted images\n",
    "            v = Visualizer(im,\n",
    "                           MetadataCatalog.get(Test_Dataset_name).set(thing_classes=Class_name),\n",
    "                           instance_mode=ColorMode.SEGMENTATION,\n",
    "                           scale=1.0\n",
    "                           )\n",
    "            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))  # do not write \"gpu\"\n",
    "            img=out.get_image()\n",
    "            result=cv2.imwrite(out_file_name, img)\n",
    "            print(\"Output predicted image: \", filename)\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data, columns=['Image name', 'Class', 'Score', 'BBox_x1', 'BBox_y1', 'BBox_x2', 'BBox_y2', 'Bbox area', 'Mask Area'])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(\"Data has been saved to\", excel_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
