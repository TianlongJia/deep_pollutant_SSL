import cv2
import detectron2.data.transforms as T
import numpy as np
import torch
from detectron2.checkpoint import DetectionCheckpointer
from detectron2.config import get_cfg
from detectron2.data import MetadataCatalog
from detectron2.data.detection_utils import read_image
from detectron2.modeling import build_model

from torch import nn

from Gradcam.gradcam import GradCAM, GradCamPlusPlus

class Detectron2GradCAM():
  """
      Attributes
    ----------
    config_file : str
        detectron2 model config file path
    model_file : str
        detectron2 model file path
    """
  def __init__(self, config_file, model_file):
      self.cfg = self._setup_cfg(config_file, model_file)

  def _setup_cfg(self, config_file, model_file):
      # load config from file, add your custom model config like RPN HEADS here
      cfg = get_cfg()
      cfg.merge_from_file(config_file)
      cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5
      cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
      cfg.MODEL.WEIGHTS = model_file
      if torch.cuda.is_available():
        cfg.MODEL.DEVICE = "cuda"
      else:
        cfg.MODEL.DEVICE = "cpu"
      cfg.freeze()
      return cfg

  def _get_input_dict(self, original_image):
      height, width = original_image.shape[:2]
      transform_gen = T.ResizeShortestEdge(
          [self.cfg.INPUT.MIN_SIZE_TEST, self.cfg.INPUT.MIN_SIZE_TEST], self.cfg.INPUT.MAX_SIZE_TEST
      )
      image = transform_gen.get_transform(original_image).apply_image(original_image)
      image = torch.as_tensor(image.astype("float32").transpose(2, 0, 1)).requires_grad_(True)
      inputs = {"image": image, "height": height, "width": width}
      return inputs

  def get_cam(self, img, target_instance, layer_name, grad_cam_type="GradCAM"):
      """
      Calls the GradCAM++ instance

      Parameters
      ----------
      img : str
          Path to inference image
      target_instance : int
          The target instance index
      layer_name : str
          Convolutional layer to perform GradCAM on
      grad_cam_type : str
          GradCAM or GradCAM++ (for multiple instances of the same object, GradCAM++ can be favorable)

      Returns
      -------
      image_dict : dict
        {"image" : <image>, "cam" : <cam>, "output" : <output>, "label" : <label>}
        <image> original input image
        <cam> class activation map resized to original image shape
        <output> instances object generated by the model
        <label> label of the 
      cam_orig : numpy.ndarray
        unprocessed raw cam
      """
      model = build_model(self.cfg)
      checkpointer = DetectionCheckpointer(model)
      checkpointer.load(self.cfg.MODEL.WEIGHTS)

      image = read_image(img, format="BRG")
      # image = cv2.imread(img)
      input_image_dict = self._get_input_dict(image)
      print("input_image_dict:", input_image_dict)

      if grad_cam_type == "GradCAM":
        grad_cam = GradCAM(model, layer_name)

      elif grad_cam_type == "GradCAM++":
        grad_cam = GradCamPlusPlus(model, layer_name)
      
      else:
        raise ValueError('Grad CAM type not specified')

      with grad_cam as cam:
        cam, cam_orig, output = cam(input_image_dict, target_category=target_instance)

      image_dict = {}
      image_dict["image"] = image
      image_dict["cam"] = cam
      image_dict["output"] = output
      image_dict["label"] = MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]).thing_classes[output[0]["instances"].pred_classes[target_instance]]

      return image_dict, cam_orig
  
  def check_num_instances(self, img):
        """
        Check the number of instances detected by the model.
        """
        model = build_model(self.cfg)
        checkpointer = DetectionCheckpointer(model)
        checkpointer.load(self.cfg.MODEL.WEIGHTS)

        input_image_dict = self._get_input_dict(read_image(img, format="BRG"))
        # input_image_dict = self._get_input_dict(cv2.imread(img))
        model.eval()
        with torch.no_grad():
            outputs = model([input_image_dict])
        
        return len(outputs[0]["instances"])



